{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import ElementClickInterceptedException, ElementNotInteractableException, NoSuchElementException, TimeoutException\n",
    "\n",
    "# Initialize the list and dictionary to store job data\n",
    "job_list = []\n",
    "job_info = {}\n",
    "\n",
    "# URL to scrape\n",
    "target_url = \"https://www.glassdoor.co.in/Job/india-data-engineer-jobs-SRCH_IL.0,5_IN115_KO6,19.htm?fromAge=7\"\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "PATH = r'C:/chromiumtest/chromedriver-win64/chromedriver.exe'\n",
    "service = Service(executable_path=PATH)\n",
    "options = Options()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Open the target URL\n",
    "driver.get(target_url)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Click \"Show More Jobs\" until the button disappears\n",
    "try:\n",
    "    while True:\n",
    "        try:\n",
    "            # Wait until the \"Show More Jobs\" button is clickable\n",
    "            load_more_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"JobsList_buttonWrapper__ticwb\"))\n",
    "            )\n",
    "            load_more_button.click()\n",
    "\n",
    "            # Wait until the \"Show More Jobs\" button is no longer stale (i.e., more jobs are loaded)\n",
    "            WebDriverWait(driver, 10).until(EC.staleness_of(load_more_button))\n",
    "        except (NoSuchElementException, ElementClickInterceptedException, ElementNotInteractableException, TimeoutException):\n",
    "            print(\"No more 'Show More Jobs' button found or it is not clickable.\")\n",
    "            break\n",
    "\n",
    "    # Get the page source after all content is loaded\n",
    "    page_source = driver.page_source\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Find the container for all job listings\n",
    "allJobsContainer = soup.find(\"ul\", {\"class\": \"JobsList_jobsList__lqjTr\"})\n",
    "if allJobsContainer:\n",
    "    # Find all individual job listings\n",
    "    allJobs = allJobsContainer.find_all(\"li\")\n",
    "\n",
    "    # Loop through each job listing to extract information\n",
    "    for job in allJobs:\n",
    "        try:\n",
    "            job_info[\"name-of-company\"] = job.find(\"div\", {\"class\": \"EmployerProfile_profileContainer__VjVBX\"}).text.strip()\n",
    "        except:\n",
    "            job_info[\"name-of-company\"] = None\n",
    "\n",
    "        try:\n",
    "            job_info[\"name-of-job\"] = job.find(\"a\", {\"class\": \"JobCard_jobTitle___7I6y\"}).text.strip()\n",
    "        except:\n",
    "            job_info[\"name-of-job\"] = None\n",
    "\n",
    "        try:\n",
    "            job_info[\"location\"] = job.find(\"div\", {\"class\": \"JobCard_location__rCz3x\"}).text.strip()\n",
    "        except:\n",
    "            job_info[\"location\"] = None\n",
    "\n",
    "        try:\n",
    "            job_info[\"salary\"] = job.find(\"div\", {\"class\": \"JobCard_salaryEstimate__arV5J\"}).text.strip()\n",
    "        except:\n",
    "            job_info[\"salary\"] = None\n",
    "\n",
    "        # Extract skills information if available\n",
    "        try:\n",
    "            skills_div = job.find(class_=\"JobCard_jobDescriptionSnippet__yWW8q\")\n",
    "            if skills_div:\n",
    "                skills_text = skills_div.get_text()\n",
    "                if \"Skills:\" in skills_text:\n",
    "                    skills = skills_text.split(\"Skills:\")[-1].strip()\n",
    "                    job_info[\"skills\"] = skills\n",
    "                else:\n",
    "                    job_info[\"skills\"] = \"Skills not found\"\n",
    "            else:\n",
    "                job_info[\"skills\"] = \"Skills not found\"\n",
    "        except:\n",
    "            job_info[\"skills\"] = \"Error extracting skills\"\n",
    "\n",
    "        # Extract posted date\n",
    "        try:\n",
    "            posted_date_div = job.find(class_=\"JobCard_listingAge__Ny_nG\")\n",
    "            job_info[\"posted-date\"] = posted_date_div.get_text().strip() if posted_date_div else \"Date not found\"\n",
    "        except:\n",
    "            job_info[\"posted-date\"] = \"Error extracting date\"\n",
    "\n",
    "        # Append the job info dictionary to the list\n",
    "        job_list.append(job_info)\n",
    "\n",
    "        # Clear the job_info dictionary for the next job\n",
    "        job_info = {}\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame and save it as a CSV file\n",
    "    df = pd.DataFrame(job_list)\n",
    "    df.to_csv('jobsweek1DE.csv', index=False, encoding='utf-8')\n",
    "\n",
    "    print(\"Scraping completed. Data saved to jobsweek1DE.csv\")\n",
    "else:\n",
    "    print(\"No job listings found.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
